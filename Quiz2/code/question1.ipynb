{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water - south carolina',\n",
       " 'evolving firearm regulations',\n",
       " 'crime analysis in south carolina',\n",
       " 'target aspect based sentiment analysis for urban neighborhoods',\n",
       " 'extracting synthesis procedure from solar cell perovskite based scientific publications.',\n",
       " 'entity recognition : water data regulations',\n",
       " \"tos: banks' terms of services summary\",\n",
       " 'water regulation summarization',\n",
       " 'predicting the 2022 gubernatorial election of south carolina using sentiment analysis of twitter.',\n",
       " 'scientific artical summarization',\n",
       " 'new fasttext [with election data]',\n",
       " 'chatbot to answer quesries regarding who water regulations ',\n",
       " 'verifying various foods connection to improve diabetes using nlp techniques ',\n",
       " 'summarization of terms and conditions',\n",
       " 'chatbot for elections faq - state of mississippi',\n",
       " 'image captioning using transformer models',\n",
       " 'specialist doctor recommendation system',\n",
       " 'application of artificial neural networks (ann) to automatic speech recognition (asr) on a novel dataset created using youtube',\n",
       " 'detecting and rating severity of urgency in short, one-time crisis events vs. ongoing ones',\n",
       " 'water regulations - arizona',\n",
       " 'damaged doc. prediction (10%)',\n",
       " 'visual question answering']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = open(\"../data/projs.txt\", \"r\")\n",
    "documents = documents.readlines()\n",
    "documents = [x.lower().split(\"\\n\")[0] for x in documents]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '2022', 'analysis', 'and', 'ann', 'answer', 'answering', 'application', 'arizona', 'artical', 'artificial', 'aspect', 'asr', 'automatic', 'banks', 'based', 'captioning', 'carolina', 'cell', 'chatbot', 'conditions', 'connection', 'created', 'crime', 'crisis', 'damaged', 'data', 'dataset', 'detecting', 'diabetes', 'doc', 'doctor', 'election', 'elections', 'entity', 'events', 'evolving', 'extracting', 'faq', 'fasttext', 'firearm', 'foods', 'for', 'from', 'gubernatorial', 'image', 'improve', 'in', 'mississippi', 'models', 'neighborhoods', 'networks', 'neural', 'new', 'nlp', 'novel', 'of', 'on', 'one', 'ones', 'ongoing', 'perovskite', 'predicting', 'prediction', 'procedure', 'publications', 'quesries', 'question', 'rating', 'recognition', 'recommendation', 'regarding', 'regulation', 'regulations', 'scientific', 'sentiment', 'services', 'severity', 'short', 'solar', 'south', 'specialist', 'speech', 'state', 'summarization', 'summary', 'synthesis', 'system', 'target', 'techniques', 'terms', 'the', 'time', 'to', 'tos', 'transformer', 'twitter', 'urban', 'urgency', 'using', 'various', 'verifying', 'visual', 'vs', 'water', 'who', 'with', 'youtube']\n",
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.4156556 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.5       0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcreidy/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(image captioning using transformer models) with 1(evolving firearm regulations) is = [[0.]]\n",
      "(image captioning using transformer models) with 2(crime analysis in south carolina) is = [[0.]]\n",
      "(image captioning using transformer models) with 3(target aspect based sentiment analysis for urban neighborhoods) is = [[0.]]\n",
      "(image captioning using transformer models) with 4(extracting synthesis procedure from solar cell perovskite based scientific publications.) is = [[0.]]\n",
      "(image captioning using transformer models) with 5(entity recognition : water data regulations) is = [[0.]]\n",
      "(image captioning using transformer models) with 6(tos: banks' terms of services summary) is = [[0.]]\n",
      "(image captioning using transformer models) with 7(water regulation summarization) is = [[0.]]\n",
      "(image captioning using transformer models) with 8(predicting the 2022 gubernatorial election of south carolina using sentiment analysis of twitter.) is = [[0.07753848]]\n",
      "(image captioning using transformer models) with 9(scientific artical summarization) is = [[0.]]\n",
      "(image captioning using transformer models) with 10(new fasttext [with election data]) is = [[0.]]\n",
      "(image captioning using transformer models) with 11(chatbot to answer quesries regarding who water regulations ) is = [[0.]]\n",
      "(image captioning using transformer models) with 12(verifying various foods connection to improve diabetes using nlp techniques ) is = [[0.08344243]]\n",
      "(image captioning using transformer models) with 13(summarization of terms and conditions) is = [[0.]]\n",
      "(image captioning using transformer models) with 14(chatbot for elections faq - state of mississippi) is = [[0.]]\n",
      "(image captioning using transformer models) with 15(image captioning using transformer models) is = [[1.]]\n",
      "(image captioning using transformer models) with 16(specialist doctor recommendation system) is = [[0.]]\n",
      "(image captioning using transformer models) with 17(application of artificial neural networks (ann) to automatic speech recognition (asr) on a novel dataset created using youtube) is = [[0.06449659]]\n",
      "(image captioning using transformer models) with 18(detecting and rating severity of urgency in short, one-time crisis events vs. ongoing ones) is = [[0.]]\n",
      "(image captioning using transformer models) with 19(water regulations - arizona) is = [[0.]]\n",
      "(image captioning using transformer models) with 20(damaged doc. prediction (10%)) is = [[0.]]\n",
      "(image captioning using transformer models) with 21(visual question answering) is = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(documents)):\n",
    "    print (\"(\" + documents[15] + \") with \" + str(i) + \"(\" + documents[i] + \") is = \"  + str(cosine_similarity (X[15], X[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projs = []\n",
    "for i in range(1, len(documents)):\n",
    "    sim = []\n",
    "    for j in range(1, len(documents)):\n",
    "        #print (\"(\" + documents[i] + \") with \" + str(i) + \"(\" + documents[j] + \") is = \"  + str(cosine_similarity (X[i], X[j])))\n",
    "        sim.append(float(cosine_similarity(X[i], X[j])))\n",
    "    projs.append(sim)\n",
    "        \n",
    "df = pd.DataFrame(projs).round(decimals=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
